{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import time\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "parentPath = os.path.abspath(\"../..\")\n",
    "if parentPath not in sys.path:\n",
    "    sys.path.insert(0, parentPath)\n",
    "\n",
    "import model as modellib\n",
    "import visualize\n",
    "from model import log\n",
    "\n",
    "%matplotlib inline \n",
    "\n",
    "# Root directory of the project\n",
    "ROOT_DIR = parentPath\n",
    "\n",
    "# Directory to save logs and trained model\n",
    "MODEL_DIR = os.path.join(ROOT_DIR, \"logs\")\n",
    "WEIGHTS_DIR = os.path.join(MODEL_DIR, \"nyu_depth_v2_scenenet20171121T1912/mask_rcnn_nyu_depth_v2_scenenet_0605.h5\")\n",
    "\n",
    "CUSTOM_DIR = \"/home/orestisz/repositories/Mask_RCNN/instance_segmentation/custom_data/static_images\"\n",
    "\n",
    "# import SceneNet\n",
    "from dataset import *\n",
    "\n",
    "def get_ax(rows=1, cols=1, size=8):\n",
    "    \"\"\"Return a Matplotlib Axes array to be used in\n",
    "    all visualizations in the notebook. Provide a\n",
    "    central point to control graph sizes.\n",
    "    \n",
    "    Change the default size attribute to control the size\n",
    "    of rendered images\n",
    "    \"\"\"\n",
    "    _, ax = plt.subplots(rows, cols, figsize=(size*cols, size*rows))\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation dataset\n",
    "dataset = Dataset()\n",
    "dataset.load(CUSTOM_DIR)\n",
    "dataset.prepare()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InferenceConfig(Config):\n",
    "    GPU_COUNT = 1\n",
    "    IMAGES_PER_GPU = 1\n",
    "\n",
    "inference_config = InferenceConfig()\n",
    "# Recreate the model in inference mode\n",
    "model = modellib.MaskRCNN(mode=\"inference\", config=inference_config, model_dir=MODEL_DIR)\n",
    "model.load_weights(WEIGHTS_DIR, by_name=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test on a random image\n",
    "image_id = random.choice(dataset.image_ids)\n",
    "# image_id = 11\n",
    "# image_id = 56\n",
    "original_image = dataset.load_image(image_id, mode=\"RGBD\")\n",
    "\n",
    "print(dataset.image_info[image_id]['path'])\n",
    "image = original_image[:, :, 0:3]\n",
    "depth = original_image[:, :, 3]\n",
    "depth_raw = original_image[:, :, 4]\n",
    "mask = original_image[:, :, 5]\n",
    "\n",
    "print(\"image_id\", image_id)\n",
    "log(\"image\", image)\n",
    "log(\"depth\", depth)\n",
    "log(\"depth_raw\", depth_raw)\n",
    "log(\"mask\", mask)\n",
    "\n",
    "depth_norm = depth / np.max(depth)\n",
    "rgbd = np.dstack((\n",
    "    image[:, :, 0] * depth_norm,\n",
    "    image[:, :, 1] * depth_norm,\n",
    "    image[:, :, 2] * depth_norm))\n",
    "\n",
    "ax = get_ax()\n",
    "ax.axis('off')\n",
    "ax.imshow(np.dstack(depth_raw / np.max(depth_raw))\n",
    "\n",
    "ax = get_ax()\n",
    "ax.axis('off')\n",
    "ax.imshow(depth_norm)\n",
    "\n",
    "ax = get_ax()\n",
    "ax.axis('off')\n",
    "ax.imshow(rgbd.astype(np.uint8))\n",
    "\n",
    "ax = get_ax()\n",
    "ax.axis('off')\n",
    "ax.imshow(image.astype(np.uint8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "for i in range(19):\n",
    "    image_id = dataset.image_ids[i]\n",
    "    original_image = dataset.load_image(image_id, mode=\"RGBD\")\n",
    "    \n",
    "    #  flip some of the images since they are on the head\n",
    "    if i > 15:\n",
    "        original_image = cv2.flip(original_image, 0)\n",
    "    \n",
    "    image = original_image[:, :, 0:3]\n",
    "    depth = original_image[:, :, 3]\n",
    "    depth_raw = original_image[:, :, 4]\n",
    "    mask = original_image[:, :, 5]\n",
    "\n",
    "    ax = get_ax()\n",
    "    ax.axis('off')\n",
    "    ax.imshow(np.dstack((255 - depth_raw,) * 3).astype(np.uint8))\n",
    "    \n",
    "    ax = get_ax()\n",
    "    ax.axis('off')\n",
    "    ax.imshow(np.dstack((255 - depth,) * 3).astype(np.uint8))\n",
    "    \n",
    "    ax = get_ax()\n",
    "    ax.axis('off')\n",
    "    ax.imshow(image.astype(np.uint8))\n",
    "    \n",
    "    #  comment out to test on grey image \n",
    "#     original_image = np.dstack((np.ones(image.shape) * 255 / 2.0, depth))\n",
    "    #  comment out to test on grey depth \n",
    "#     original_image = np.dstack((image, np.ones(depth.shape) * 255 / 2.0))\n",
    "\n",
    "    start = time.clock()\n",
    "    r = model.detect([original_image[:, :, 0:4]])[0]\n",
    "    print(time.clock() - start)\n",
    "\n",
    "    #  comment out to show individual masks  \n",
    "#     for i, roi in enumerate(r['rois']):\n",
    "#         roi = np.array([roi])\n",
    "#         mask = np.expand_dims(np.array(r['masks'][:, :, i]), 2)\n",
    "#         class_id = np.array([r['class_ids'][i]])\n",
    "#         score = np.array([r['scores'][i]])\n",
    "#         visualize.display_instances(image, roi, mask, class_id, \n",
    "#                         dataset.class_names, score, ax=get_ax(), colors=[[0, 1, 0]])\n",
    "\n",
    "    visualize.display_instances(image, r['rois'], r['masks'], r['class_ids'], \n",
    "                        dataset.class_names, r['scores'], ax=get_ax())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
