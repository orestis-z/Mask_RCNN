{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import re\n",
    "import time\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "parentPath = os.path.abspath(\"../..\")\n",
    "if parentPath not in sys.path:\n",
    "    sys.path.insert(0, parentPath)\n",
    "\n",
    "import model as modellib\n",
    "import visualize\n",
    "from model import log\n",
    "\n",
    "%matplotlib inline \n",
    "\n",
    "# Root directory of the project\n",
    "ROOT_DIR = parentPath\n",
    "\n",
    "# Directory to save logs and trained model\n",
    "MODEL_DIR = os.path.join(ROOT_DIR, \"logs\")\n",
    "# MODEL_DIR = os.path.join(\"/data/orestisz/logs\")\n",
    "\n",
    "SCENENN_DIR = \"/external_datasets/SceneNet_RGBD\"\n",
    "# SCENENET_MODEL_PATH = os.path.join(MODEL_DIR, \"scenenet20180428T1942/mask_rcnn_scenenet_0576.h5\")\n",
    "# SCENENET_MODEL_PATH = os.path.join(MODEL_DIR, \"scenenet_coco_rgb20180428T1942/mask_rcnn_scenenet_coco_rgb_0600.h5\")\n",
    "# SCENENET_MODEL_PATH = os.path.join(MODEL_DIR, \"scenenet_classes20180428T1942/mask_rcnn_scenenet_classes_0700.h5\")\n",
    "SCENENET_MODEL_PATH = os.path.join(MODEL_DIR, \"scenenet_coco_rgb_classes20180428T1942/mask_rcnn_scenenet_coco_rgb_classes_0700.h5\")\n",
    "# MODEL_PATH = os.path.join(ROOT_DIR, \"mask_rcnn_coco.h5\")\n",
    "\n",
    "# import SceneNet\n",
    "from dataset import *\n",
    "\n",
    "def get_ax(rows=1, cols=1, size=8):\n",
    "    \"\"\"Return a Matplotlib Axes array to be used in\n",
    "    all visualizations in the notebook. Provide a\n",
    "    central point to control graph sizes.\n",
    "    \n",
    "    Change the default size attribute to control the size\n",
    "    of rendered images\n",
    "    \"\"\"\n",
    "    _, ax = plt.subplots(rows, cols, figsize=(size*cols, size*rows))\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Validation dataset\n",
    "dataset_test = Dataset()\n",
    "dataset_test.load(\"validation\")\n",
    "dataset_test.prepare()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "class InferenceConfig(Config):\n",
    "    GPU_COUNT = 1\n",
    "    IMAGES_PER_GPU = 1\n",
    "\n",
    "config = InferenceConfig()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Test on a random image\n",
    "image_id = random.choice(dataset_test.image_ids)\n",
    "# image_id = 11173\n",
    "# image_id = 72081\n",
    "# image_id = 199013\n",
    "print(\"image_id\", image_id)\n",
    "\n",
    "original_image, image_meta, class_ids, bbox, mask=\\\n",
    "    modellib.load_image_gt(dataset_test, config, \n",
    "                           image_id, use_mini_mask=False)\n",
    "print(dataset_test.image_info[image_id]['path'])\n",
    "\n",
    "image = original_image[:, :, 0:3]\n",
    "log(\"image\", image)\n",
    "log(\"image_meta\", image_meta)\n",
    "log(\"bbox\", bbox)\n",
    "log(\"mask\", mask)\n",
    "\n",
    "if len(config.MODE) > 3:\n",
    "    depth = original_image[:, :, 3]\n",
    "    depth = depth.astype(np.uint8)\n",
    "    depth_norm = depth / np.max(depth)\n",
    "    log(\"depth\", depth)\n",
    "    rgbd = np.dstack((\n",
    "        image[:, :, 0] * depth_norm,\n",
    "        image[:, :, 1] * depth_norm,\n",
    "        image[:, :, 2] * depth_norm))\n",
    "\n",
    "    ax = get_ax()\n",
    "    ax.axis('off')\n",
    "    ax.imshow(depth_norm)\n",
    "\n",
    "    ax = get_ax()\n",
    "    ax.axis('off')\n",
    "    ax.imshow(rgbd.astype(np.uint8))\n",
    "else:\n",
    "    ax = get_ax()\n",
    "    ax.axis('off')\n",
    "    ax.imshow(image.astype(np.uint8))\n",
    "\n",
    "visualize.display_top_masks(image, mask, class_ids, dataset_test.class_names, limit=1)\n",
    "visualize.display_instances(image, bbox, mask, class_ids, dataset_test.class_names, figsize=(8, 8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Recreate the model in inference mode\n",
    "model = modellib.MaskRCNN(mode=\"inference\", config=config, model_dir=MODEL_DIR)\n",
    "model.load_weights(SCENENET_MODEL_PATH, by_name=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# %%script false\n",
    "if False: # test transfer weights rgb -> rgbd\n",
    "    # get weights from first convolution\n",
    "    conv1 = model.keras_model.get_layer(\"conv1\")\n",
    "    kernel_rgb, bias = conv1.get_weights()\n",
    "\n",
    "    # reload model in rgb-d mode\n",
    "    config_rgbd = InferenceConfig()\n",
    "    config_rgbd.MODE = \"RGBD\"\n",
    "    config_rgbd.MEAN_PIXEL = np.array([123.7, 116.8, 103.9, 255 / 2])\n",
    "    config_rgbd.IMAGE_SHAPE = np.array([config.IMAGE_MAX_DIM, config.IMAGE_MAX_DIM, 4])\n",
    "    model_rgbd = modellib.MaskRCNN(mode=\"inference\", config=config_rgbd, model_dir=MODEL_DIR)\n",
    "    model_rgbd.load_weights(SCENENET_MODEL_PATH, by_name=True, exclude=[\"conv1\"])\n",
    "\n",
    "    # set weights on first convolution from rgb model\n",
    "    conv1 = model_rgbd.keras_model.get_layer(\"conv1\")\n",
    "    kernel_rgbd = np.concatenate((kernel_rgb, np.mean(kernel_rgb, keepdims=True, axis=2)), axis=2)\n",
    "#     kernel_rgbd = np.concatenate((kernel_rgb, np.zeros((7, 7, 1, 64))), axis=2)\n",
    "    conv1.set_weights([kernel_rgbd, bias])\n",
    "    original_image, _, _, _, _ = modellib.load_image_gt(dataset_test, config_rgbd, image_id, use_mini_mask=False)\n",
    "    \n",
    "    start = time.clock()\n",
    "    r = model_rgbd.detect([original_image])[0]\n",
    "    print(time.clock() - start)\n",
    "    visualize.display_instances(original_image[:, :, 0:3], r['rois'], r['masks'], r['class_ids'], \n",
    "                        dataset_test.class_names, r['scores'], ax=get_ax())\n",
    "else:\n",
    "    delta = []\n",
    "    for idx, image_id in enumerate(dataset_test.image_ids[0::1000]):\n",
    "        original_image, image_meta, class_ids, bbox, mask=\\\n",
    "        modellib.load_image_gt(dataset_test, config, \n",
    "                           image_id, use_mini_mask=False)\n",
    "\n",
    "        image = original_image[:, :, 0:3]\n",
    "\n",
    "        start = time.clock()\n",
    "        r = model.detect([original_image])[0]\n",
    "        print(time.clock() - start)\n",
    "        if (idx):\n",
    "            delta.append(time.clock() - start)\n",
    "        visualize.display_instances(image, r['rois'], r['masks'], r['class_ids'], \n",
    "                            dataset_test.class_names, r['scores'], ax=get_ax(),\n",
    "                            title=\"sceneNet_classes/{}_{}\".format(image_id, config.MODE))\n",
    "        \n",
    "    print(\"avarage delta: \", np.mean(delta))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%%script false\n",
    "import utils\n",
    "# Compute VOC-Style mAP @ IoU=0.5\n",
    "# Running on 10 images. Increase for better accuracy.\n",
    "image_ids = dataset_test.image_ids[0::30]\n",
    "APs_50 = []\n",
    "APs_75 = []\n",
    "APs_50_95 = []\n",
    "for i, image_id in enumerate(image_ids):\n",
    "    # Load image and ground truth data\n",
    "    image_path = dataset_test.image_info[image_id]['path']\n",
    "    try:\n",
    "        image, image_meta, gt_class_id, gt_bbox, gt_mask  =\\\n",
    "            modellib.load_image_gt(dataset_test, config,\n",
    "                                   image_id, use_mini_mask=False)\n",
    "        # Run object detection\n",
    "        results = model.detect([image], verbose=0)\n",
    "        r = results[0]\n",
    "        # Compute AP\n",
    "        AP_50, precisions, recalls, overlaps =\\\n",
    "            utils.compute_ap(gt_bbox, gt_class_id, gt_mask,\n",
    "                             r[\"rois\"], r[\"class_ids\"], r[\"scores\"], r['masks'], iou_threshold=0.5)\n",
    "        AP_75, precisions, recalls, overlaps =\\\n",
    "            utils.compute_ap(gt_bbox, gt_class_id, gt_mask,\n",
    "                             r[\"rois\"], r[\"class_ids\"], r[\"scores\"], r['masks'], iou_threshold=0.75)\n",
    "        AP_50_95 =\\\n",
    "            utils.compute_ap_range(gt_bbox, gt_class_id, gt_mask,\n",
    "                             r[\"rois\"], r[\"class_ids\"], r[\"scores\"], r['masks'], verbose=0)\n",
    "        \n",
    "        APs_50.append(AP_50)\n",
    "        APs_75.append(AP_75)\n",
    "        APs_50_95.append(AP_50_95)\n",
    "\n",
    "#         print('{}: {}: {}, {}, {}'.format(i + 1, image_path, AP_50, AP_75, AP_50_95))\n",
    "    except:\n",
    "        print(\"Error processing image {}\".format(image_path))\n",
    "\n",
    "print(\"mAP@IoU=0.5: \", np.mean(APs_50))\n",
    "print(\"mAP@IoU=0.75: \", np.mean(APs_75))\n",
    "print(\"mAP@IoU=0.5:0.95: \", np.mean(APs_50_95))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
