{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import re\n",
    "import time\n",
    "import random\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "parentPath = os.path.abspath(\"../..\")\n",
    "if parentPath not in sys.path:\n",
    "    sys.path.insert(0, parentPath)\n",
    "\n",
    "import model as modellib\n",
    "import visualize\n",
    "from model import log\n",
    "\n",
    "%matplotlib inline \n",
    "\n",
    "# Root directory of the project\n",
    "ROOT_DIR = parentPath\n",
    "\n",
    "# Directory to save logs and trained model\n",
    "MODEL_DIR = os.path.join(ROOT_DIR, \"logs\")\n",
    "\n",
    "# Path to COCO trained weights\n",
    "COCO_MODEL_PATH = os.path.join(ROOT_DIR, \"mask_rcnn_coco.h5\")\n",
    "\n",
    "ADE20K_DIR = \"/home/orestisz/data/ADE20K_2016_07_26\"\n",
    "COCO_DIR = \"/home/orestisz/repositories/coco\"\n",
    "SCENENN_DIR = \"/home/orestisz/data/sceneNN\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import coco\n",
    "\n",
    "# import ADE20K\n",
    "from dataset import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def get_ax(rows=1, cols=1, size=8):\n",
    "    \"\"\"Return a Matplotlib Axes array to be used in\n",
    "    all visualizations in the notebook. Provide a\n",
    "    central point to control graph sizes.\n",
    "    \n",
    "    Change the default size attribute to control the size\n",
    "    of rendered images\n",
    "    \"\"\"\n",
    "    _, ax = plt.subplots(rows, cols, figsize=(size*cols, size*rows))\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# # coco dataset\n",
    "dataset_coco = coco.CocoDataset()\n",
    "dataset_coco.load_coco(COCO_DIR, \"minival\")\n",
    "dataset_coco.prepare()\n",
    "\n",
    "# Validation dataset\n",
    "dataset_val = Dataset()\n",
    "dataset_val.load(ADE20K_DIR, \"validation\")\n",
    "dataset_val.prepare()\n",
    "\n",
    "# import object_segmentation.sceneNN.dataset as dataset_sceneNN\n",
    "# dataset_sceneNN_test = dataset_sceneNN.Dataset()\n",
    "# dataset_sceneNN_test.load(SCENENN_DIR, \"testing\")\n",
    "# dataset_sceneNN_test.prepare()\n",
    "\n",
    "# dataset = dataset_sceneNN_test\n",
    "dataset = dataset_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# class InferenceConfig(dataset_sceneNN.Config):\n",
    "class InferenceConfig(Config):\n",
    "    GPU_COUNT = 1\n",
    "    IMAGES_PER_GPU = 1\n",
    "class InferenceConfigCoco(coco.CocoConfig):\n",
    "    GPU_COUNT = 1\n",
    "    IMAGES_PER_GPU = 1\n",
    "\n",
    "inference_config = InferenceConfig()\n",
    "inference_config_coco = InferenceConfigCoco()\n",
    "# Recreate the model in inference mode\n",
    "model = modellib.MaskRCNN(mode=\"inference\", config=inference_config, model_dir=MODEL_DIR)\n",
    "model_coco = modellib.MaskRCNN(mode=\"inference\", config=inference_config_coco, model_dir=MODEL_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Test on a random image\n",
    "image_id = random.choice(dataset.image_ids)\n",
    "original_image, image_meta, class_ids, bbox, mask =\\\n",
    "    modellib.load_image_gt(dataset, inference_config, \n",
    "                           image_id, use_mini_mask=False)\n",
    "    \n",
    "log(\"original_image\", original_image)\n",
    "log(\"image_meta\", image_meta)\n",
    "log(\"bbox\", bbox)\n",
    "log(\"mask\", mask)\n",
    "visualize.display_top_masks(original_image, mask, class_ids, dataset.class_names, limit=1)\n",
    "\n",
    "visualize.display_instances(original_image, bbox, mask, class_ids, \n",
    "                            dataset.class_names, figsize=(8, 8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# coco model\n",
    "print(\"Loading weights from Coco Model with all classes\")\n",
    "model_coco.load_weights(COCO_MODEL_PATH, by_name=True)\n",
    "r = model_coco.detect([original_image])[0]\n",
    "visualize.display_instances(original_image, r['rois'], r['masks'], r['class_ids'], \n",
    "                            dataset_coco.class_names, r['scores'], title='coco', ax=get_ax())\n",
    "\n",
    "skip = 3\n",
    "model_paths = model.find_all()\n",
    "for model_path in model_paths:\n",
    "    print(\"Loading weights from \", model_path[0])\n",
    "    for i, checkpoint in enumerate(model_path[1]):\n",
    "        if i % (skip + 1) == 0:\n",
    "            print(\"    \" + checkpoint)\n",
    "            model.load_weights(checkpoint, by_name=True)\n",
    "            start = time.clock()\n",
    "            r = model.detect([original_image])[0]\n",
    "            print(time.clock() - start)\n",
    "            visualize.display_instances(original_image, r['rois'], r['masks'], r['class_ids'], \n",
    "                                dataset.class_names, r['scores'], title=checkpoint, ax=get_ax())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Compute VOC-Style mAP @ IoU=0.5\n",
    "# Running on 10 images. Increase for better accuracy.\n",
    "image_ids = np.random.choice(dataset.image_ids, 20)\n",
    "APs = []\n",
    "for i, image_id in enumerate(image_ids):\n",
    "    # Load image and ground truth data\n",
    "    try:\n",
    "        image_path = dataset.image_info[image_id]['path']\n",
    "        image, image_meta, gt_class_id, gt_bbox, gt_mask =\\\n",
    "            modellib.load_image_gt(dataset, inference_config,\n",
    "                                   image_id, use_mini_mask=False)\n",
    "        # Run object detection\n",
    "        results = model.detect([image], verbose=0)\n",
    "        r = results[0]\n",
    "        # Compute AP\n",
    "        AP, precisions, recalls, overlaps =\\\n",
    "            utils.compute_ap(gt_bbox, gt_class_id, r[\"rois\"], r[\"class_ids\"], r[\"scores\"])\n",
    "        APs.append(AP)\n",
    "        print('{}: {}: {}'.format(i + 1, image_path, AP))\n",
    "    except:\n",
    "        print(\"Error processing image {}\".format(image_path))\n",
    "    \n",
    "print(\"mAP: \", np.mean(APs))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
