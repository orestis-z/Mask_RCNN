{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import re\n",
    "import time\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "parentPath = os.path.abspath(\"../..\")\n",
    "if parentPath not in sys.path:\n",
    "    sys.path.insert(0, parentPath)\n",
    "\n",
    "import model as modellib\n",
    "import visualize\n",
    "from model import log\n",
    "\n",
    "%matplotlib inline \n",
    "\n",
    "# Root directory of the project\n",
    "ROOT_DIR = parentPath\n",
    "\n",
    "# Directory to save logs and trained model\n",
    "MODEL_DIR = os.path.join(ROOT_DIR, \"logs\")\n",
    "\n",
    "SCENENN_DIR = \"/external_datasets/sceneNN\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# import sceneNN\n",
    "from dataset import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def get_ax(rows=1, cols=1, size=8):\n",
    "    \"\"\"Return a Matplotlib Axes array to be used in\n",
    "    all visualizations in the notebook. Provide a\n",
    "    central point to control graph sizes.\n",
    "    \n",
    "    Change the default size attribute to control the size\n",
    "    of rendered images\n",
    "    \"\"\"\n",
    "    _, ax = plt.subplots(rows, cols, figsize=(size*cols, size*rows))\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Validation dataset\n",
    "dataset_test = ObjectsDataset()\n",
    "dataset_test.load(SCENENN_DIR, \"testing\", skip=59)\n",
    "dataset_test.prepare()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "class InferenceConfig(ObjectsConfig):\n",
    "    GPU_COUNT = 1\n",
    "    IMAGES_PER_GPU = 1\n",
    "\n",
    "inference_config = InferenceConfig()\n",
    "# Recreate the model in inference mode\n",
    "model = modellib.MaskRCNN(mode=\"inference\", config=inference_config, model_dir=MODEL_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Test on a random image\n",
    "image_id = random.choice(dataset_test.image_ids)\n",
    "# image_id = 328\n",
    "original_image, image_meta, class_ids, bbox, mask=\\\n",
    "    modellib.load_image_gt(dataset_test, inference_config, \n",
    "                           image_id, use_mini_mask=False)\n",
    "print(dataset_test.image_info[image_id]['path'])\n",
    "image = original_image[:, :, 0:3]\n",
    "depth = original_image[:, :, 3]\n",
    "print(\"image_id\", image_id)\n",
    "log(\"image\", image)\n",
    "log(\"depth\", depth)\n",
    "log(\"image_meta\", image_meta)\n",
    "log(\"bbox\", bbox)\n",
    "log(\"mask\", mask)\n",
    "\n",
    "depth_norm = 1.0 - depth / np.max(depth)\n",
    "rgbd = np.dstack((\n",
    "    image[:, :, 0] * depth_norm,\n",
    "    image[:, :, 1] * depth_norm,\n",
    "    image[:, :, 2] * depth_norm))\n",
    "rgbd = rgbd.astype(np.uint8)\n",
    "depth = np.dstack((depth_norm * 255,) * 3)\n",
    "depth = depth.astype(np.uint8)\n",
    "\n",
    "ax = get_ax()\n",
    "ax.axis('off')\n",
    "ax.imshow(depth)\n",
    "\n",
    "ax = get_ax()\n",
    "ax.axis('off')\n",
    "ax.imshow(rgbd)\n",
    "\n",
    "visualize.display_top_masks(image, mask, class_ids, dataset_test.class_names, limit=1)\n",
    "\n",
    "visualize.display_instances(image, bbox, mask, class_ids, dataset_test.class_names, figsize=(8, 8))\n",
    "# visualize.display_instances(depth, bbox, mask, class_ids, dataset_test.class_names, figsize=(8, 8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# model_paths = model.find_all()\n",
    "# for model_path in model_paths:\n",
    "#     print(\"Loading weights from \", model_path[0])\n",
    "#     for checkpoint in model_path[1]:\n",
    "#         print(\"    \" + checkpoint)\n",
    "        # model.load_weights(checkpoint, by_name=True)\n",
    "model.load_weights(model.find_last()[1], by_name=True)\n",
    "# MODEL_PATH = os.path.join(ROOT_DIR, \"logs/seg_scenenn20171109T1726/mask_rcnn_seg_scenenn_0115.h5\")\n",
    "model.load_weights(MODEL_PATH, by_name=True)\n",
    "start = time.clock()\n",
    "r = model.detect([original_image])[0]\n",
    "print(time.clock() - start)\n",
    "visualize.display_instances(image, r['rois'], r['masks'], r['class_ids'], \n",
    "                    dataset_test.class_names, r['scores'], ax=get_ax())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%script false\n",
    "# Compute VOC-Style mAP @ IoU=0.5\n",
    "# Running on 10 images. Increase for better accuracy.\n",
    "image_ids = np.random.choice(dataset_test.image_ids, 50)\n",
    "APs = []\n",
    "for i, image_id in enumerate(image_ids):\n",
    "    # Load image and ground truth data\n",
    "    image_path = dataset_test.image_info[image_id]['path']\n",
    "    try:\n",
    "        image, image_meta, gt_class_id, gt_bbox, gt_mask  =\\\n",
    "            modellib.load_image_gt(dataset_test, inference_config,\n",
    "                                   image_id, use_mini_mask=False)\n",
    "        # Run object detection\n",
    "        results = model.detect([image], verbose=0)\n",
    "        r = results[0]\n",
    "        # Compute AP\n",
    "        AP, precisions, recalls, overlaps =\\\n",
    "            utils.compute_ap(gt_bbox, gt_class_id, r[\"rois\"], r[\"class_ids\"], r[\"scores\"])\n",
    "        APs.append(AP)\n",
    "        print('{}: {}: {}: {}'.format(i + 1, image_id, image_path, AP))\n",
    "    except:\n",
    "        print(\"Error processing image {}\".format(image_path))\n",
    "\n",
    "print(\"mAP: \", np.mean(APs))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
